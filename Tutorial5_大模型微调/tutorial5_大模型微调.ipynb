{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial5: 大模型微调\n",
    "\n",
    "本节旨在通过 [cpm-bee-2b](https://huggingface.co/openbmb/cpm-bee-2b) 模型来展示大模型微调。\n",
    "\n",
    "分以下几步来实现：\n",
    "1. 环境安装\n",
    "2. 下载模型\n",
    "3. 上传数据集\n",
    "4. 模型微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境安装\n",
    "\n",
    "我们默认用户已经按照 [tutorial_scow_for_ai](../tutorial_scow_for_ai.md) 在 “交互式应用” 中创建了  Jupyter Lab 应用，并已经安装了 conda。现在需要在命令行中创建环境并注册 ipykernal：\n",
    "\n",
    "```bash\n",
    "conda create --name cpm-bee python=3.9\n",
    "conda activate cpm-bee\n",
    "# 安装内核\n",
    "conda install ipykernel\n",
    "# 注册内核\n",
    "python -m ipykernel install --user --name=cpm-bee --display-name=\"cpm-bee\"\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "pip install deepspeed accelerate==0.30.1 transformers==4.33.2\n",
    "```\n",
    "\n",
    "（ pytorch 版本需与 cuda 版本对应，请查看版本对应网站：https://pytorch.org/get-started/previous-versions ，通过 nvidia-smi 命令可查看 cuda 版本）\n",
    "\n",
    "打开本 .ipynb 文件并选择 kernel 为 cpm-bee。硬件资源建议使用1张GPU运行。\n",
    "\n",
    "CUDA Version: 12.1; Torch Version: 2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 下载模型\n",
    "\n",
    "CPM-Bee 是一个完全开源、可商用的中英双语基础模型，拥有一百亿参数的容量。我们这里选用的是较小参数的 cpm-bee-2b 模型。在联网的命令行中执行以下命令，命令执行位置在当前文件所在的文件夹。\n",
    "\n",
    "```bash\n",
    "# 如果以下目录存在， 可以直接复制:\n",
    "cp -r /lustre/public/tutorial/models/cpm-bee-2b/ ./\n",
    "\n",
    "# 否则请自行下载：\n",
    "export HF_ENDPOINT=https://hf-mirror.com\n",
    "huggingface-cli download --resume-download openbmb/cpm-bee-2b --local-dir cpm-bee-2b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 上传数据集\n",
    "\n",
    "可以自行上传数据，我们这里准备了数据 bee_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 微调\n",
    "\n",
    "```bash\n",
    "accelerate config\n",
    "```\n",
    "\n",
    "生成的配置文件在 ~/.cache/huggingface/accelerate/default_config.yaml 下，内容为：\n",
    "\n",
    "```yaml\n",
    "compute_environment: LOCAL_MACHINE                                 \n",
    "debug: false\n",
    "distributed_type: MULTI_GPU\n",
    "downcast_bf16: 'no'\n",
    "enable_cpu_affinity: false\n",
    "gpu_ids: all\n",
    "machine_rank: 0\n",
    "main_training_function: main\n",
    "mixed_precision: fp16\n",
    "num_machines: 1\n",
    "num_processes: 4\n",
    "rdzv_backend: static\n",
    "same_network: true\n",
    "tpu_env: []\n",
    "tpu_use_cluster: false\n",
    "tpu_use_sudo: false\n",
    "use_cpu: false\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "code = '''import json\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CPMDataset(Dataset):\n",
    "    def __init__(self, jsonl_file):\n",
    "        self.data = []\n",
    "        with open(jsonl_file, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                # 解析每一行 JSON 数据\n",
    "                item = json.loads(line)\n",
    "                # 提取需要的字段\n",
    "                input_text = item['input']\n",
    "                answer = item['<ans>']\n",
    "                # 将数据添加到列表中\n",
    "                self.data.append({\"input\": input_text, \"<ans>\": answer})\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集的大小\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 返回格式化的数据\n",
    "        return self.data[idx]\n",
    "'''\n",
    "\n",
    "with open('data_prepare.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo '''from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from accelerate import Accelerator\n",
    "from data_prepare import CPMDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# 数据准备\n",
    "trainset = CPMDataset(\"bee_data/train.jsonl\")  \n",
    "train_loader = DataLoader(trainset, batch_size=1)\n",
    "\n",
    "# 模型\n",
    "model_path = \"cpm-bee-1b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "# 训练\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_loader = accelerator.prepare(\n",
    "    model, optimizer, train_loader\n",
    ")\n",
    "\n",
    "# 计时\n",
    "total_time = 0\n",
    "\n",
    "for iter, data in enumerate(train_loader):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    step_start = time.perf_counter()\n",
    "    \n",
    "    # 训练\n",
    "    optimizer.zero_grad()\n",
    "    input_encoded = tokenizer.prepare_for_finetune(data, max_length=512)\n",
    "    outputs = model(**input_encoded)\n",
    "    loss = outputs.loss\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    \n",
    "    step_time = time.perf_counter() - step_start\n",
    "    total_time += step_time\n",
    "    \n",
    "    # 仅在主进程输出\n",
    "    if accelerator.is_main_process:\n",
    "        print(f\"Step {iter}, Loss: {loss.item():.4f}, Time per step: {step_time:.4f} s\")\n",
    "\n",
    "    \n",
    "# 仅在主进程输出\n",
    "if accelerator.is_main_process:\n",
    "    print(\"Training done\")\n",
    "    print(f\"Total training time: {total_time:.2f} s\")\n",
    "    print(f\"Average time per step: {total_time / (iter + 1):.4f} s\")\n",
    "''' > cpm-bee-train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在命令行中执行：\n",
    "\n",
    "```bash\n",
    "accelerate launch cpm-bee-train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> 作者: 黎颖; 龙汀汀\n",
    ">\n",
    "> 联系方式: yingliclaire@pku.edu.cn;   l.tingting@pku.edu.cn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
